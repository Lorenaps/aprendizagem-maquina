{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Linear Multipla com NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando bibliotecas a serem utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importanto os dados do arquivo sample_treino.csv\n",
    "Após recuperar as informações do aquivo utiliza-se a blibioteca numpy para criar os respectivos vetores com \n",
    "as variáveis independentes em **X** e a variável dependente em **Y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.genfromtxt(\"../datasets/sample_treino.csv\", delimiter=\",\")\n",
    "\n",
    "points = np.c_[np.ones(len(points)),points]\n",
    "X = points[1:,[0,1,2,3,4,5]]\n",
    "Y = points[1:,6][:,np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versão Vetorizada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$MSE(\\hat{w})=\\frac{1}{N}(y-\\hat{\\mathbf{w}}^T\\mathbf{x})^T(y-\\hat{\\mathbf{w}}^T\\mathbf{x})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Função para calcular o MSE (Mean squared error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# totalError = 0\n",
    "#     for i in range(0, len(points)):\n",
    "#         x = points[i, 0]\n",
    "#         y = points[i, 1]\n",
    "#         totalError += (y - (m * x + b)) ** 2\n",
    "#     return totalError / float(len(points))\n",
    "\n",
    "def compute_mse_vectorized(w,X,Y):\n",
    "    res = Y - np.dot(X,w)\n",
    "    totalError = np.dot(res.T,res)\n",
    "    return totalError / float(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# b_gradient = 0\n",
    "#     m_gradient = 0\n",
    "#     for i in range(0, len(points)):\n",
    "#         x = points[i, 0]\n",
    "#         y = points[i, 1]\n",
    "#         b_gradient += (y - ((m_current * x) + b_current))\n",
    "#         m_gradient += x * (y - ((m_current * x) + b_current))\n",
    "#     new_b = b_current + (2 * learningRate * b_gradient)\n",
    "#     new_m = m_current + (2 * learningRate * m_gradient)\n",
    "#     return [new_b, new_m, b_gradient, m_gradient]\n",
    "\n",
    "def step_gradient_vectorized(w_current,X,Y,learningRate):\n",
    "    res = Y - np.dot(X,w_current)\n",
    "    b_gradient = np.sum(res)\n",
    "    X = X[:,1][:,np.newaxis]\n",
    "    m_gradient = np.sum(np.multiply(res,X))\n",
    "    new_w = np.array([(w_current[0] + (2 * learningRate * b_gradient)),\n",
    "             (w_current[1] + (2 * learningRate * m_gradient))])\n",
    "    return [new_w,b_gradient,m_gradient]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# c=0\n",
    "# for i in range(len(x)):\n",
    "#     c += x[i]**2\n",
    "# return math.sqrt(c)\n",
    "\n",
    "# def gradient_descent_runner(points, starting_b, starting_m, learning_rate, epsilon):\n",
    "#     b = starting_b\n",
    "#     m = starting_m\n",
    "#     grad = np.array([np.inf,np.inf])\n",
    "#     i = 0\n",
    "#     while (norm_2(grad)>=epsilon):\n",
    "#         b, m, b_gradient, m_gradient = step_gradient(b, m, points, learning_rate)\n",
    "#         grad = np.array([b_gradient,m_gradient])\n",
    "#         if i % 1000 == 0:\n",
    "#             #print(norm_2(grad))\n",
    "#             print(\"MSE na iteração {0} é de {1}\".format(i,compute_mse(b,m,points)))\n",
    "#         i+= 1\n",
    "#     return [b, m]\n",
    "\n",
    "def gradient_descent_runner_vectorized(starting_w, X,Y, learning_rate, epsilon):\n",
    "    w = starting_w\n",
    "    grad = np.array([np.inf,np.inf])\n",
    "    i = 0\n",
    "    while (np.linalg.norm(grad)>=epsilon):\n",
    "        w,b_gradient,m_gradient = step_gradient_vectorized(w, X, Y, learning_rate)\n",
    "        grad = np.array([b_gradient,m_gradient])\n",
    "        #print(np.linalg.norm(grad))\n",
    "        if i % 1000 == 0:\n",
    "            print(\"MSE na iteração {0} é de {1}\".format(i,compute_mse_vectorized(w, X, Y)))\n",
    "        i+= 1\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gradient descent at w0 = [ 0.], w1 = [ 0.], error = [[ 2946.63449705]]\n",
      "Running...\n",
      "MSE na iteração 0 é de [[ 1192.54554729]]\n",
      "MSE na iteração 1000 é de [[ 72.17883367]]\n",
      "MSE na iteração 2000 é de [[ 53.76174367]]\n",
      "MSE na iteração 3000 é de [[ 43.35384055]]\n",
      "MSE na iteração 4000 é de [[ 37.4721053]]\n",
      "MSE na iteração 5000 é de [[ 34.14820718]]\n",
      "MSE na iteração 6000 é de [[ 32.26979916]]\n",
      "MSE na iteração 7000 é de [[ 31.20826943]]\n",
      "MSE na iteração 8000 é de [[ 30.60837559]]\n",
      "MSE na iteração 9000 é de [[ 30.26936238]]\n",
      "MSE na iteração 10000 é de [[ 30.07777855]]\n",
      "MSE na iteração 11000 é de [[ 29.9695103]]\n",
      "MSE na iteração 12000 é de [[ 29.90832554]]\n",
      "MSE na iteração 13000 é de [[ 29.87374868]]\n",
      "MSE na iteração 14000 é de [[ 29.85420853]]\n",
      "MSE na iteração 15000 é de [[ 29.84316597]]\n",
      "MSE na iteração 16000 é de [[ 29.83692557]]\n",
      "Gradiente descendente convergiu com w0 = [-39.09650898], w1 = [ 5.57866311], error = [[ 29.83465362]]\n",
      "Versão vetorizada rodou em: 490.15092849731445 ms\n"
     ]
    }
   ],
   "source": [
    "points = np.genfromtxt(\"../datasets/sample_treino.csv\", delimiter=\",\")\n",
    "points = np.c_[np.ones(len(points)),points]\n",
    "X = points[:,[0,1]]\n",
    "Y = points[:,2][:,np.newaxis]\n",
    "init_w = np.zeros((2,1))\n",
    "learning_rate = 0.0001\n",
    "#num_iterations = 10000\n",
    "epsilon = 0.5\n",
    "print(\"Starting gradient descent at w0 = {0}, w1 = {1}, error = {2}\".format(init_w[0], init_w[1], compute_mse_vectorized(init_w, X,Y)))\n",
    "print(\"Running...\")\n",
    "tic = time.time()\n",
    "w = gradient_descent_runner_vectorized(init_w, X,Y, learning_rate, epsilon)\n",
    "toc = time.time()\n",
    "print(\"Gradiente descendente convergiu com w0 = {0}, w1 = {1}, error = {2}\".format(w[0], w[1], compute_mse_vectorized(w,X,Y)))\n",
    "print(\"Versão vetorizada rodou em: \" + str(1000*(toc-tic)) + \" ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão linear multipla com a bilbioteca Scikit Learn\n",
    "\n",
    "[Documentação da biblioteca](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression) - Descrição dos métodos e atributos a serem utilizados para montar um modelo preditivo com esse recurso\n",
    "\n",
    "Para treinar o modelo utiliza-se a função do módulo *linear_model* **fit** e para imprimir os coeficientes a função **coef_**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.10304143,  0.0464367 ,  0.16409834,  0.38117843,\n",
       "         0.02027816]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "reg.fit(X, Y)\n",
    "\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
